{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536676a0-ce28-4038-b193-8033a1cf2de6",
   "metadata": {},
   "source": [
    "## Search \"ECB guide to internal models\"\n",
    "\n",
    "**A. Get Questions and Embeddings**:\n",
    "- Load ECB Guide embeddings from a pickle file.\n",
    "- Convert string embeddings to numpy arrays.\n",
    "- Import questions from an Excel file.\n",
    "\n",
    "**B. Helper Functions**:\n",
    "- `search_docs`: Search documents and rank them based on cosine similarity of embeddings.\n",
    "- `create_embedding`: Generate an embedding for a search phrase.\n",
    "- `test_answers`: Test the questions against the embeddings to get relevant answers.\n",
    "- `display_rows`: Display specified rows from a DataFrame in a given format.\n",
    "\n",
    "**C. Conduct Testing**:\n",
    "- Run the `test_answers` function and display the top results.\n",
    "\n",
    "**D. Perform Manual Testing**\n",
    "- Conduct manual testing for specific queries and display the top 3 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14cc9aa7-f831-4c2e-9cdc-f337f34d729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import time\n",
    "import tiktoken\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Settings\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015ab4a-0555-4566-81a3-399396ca36b1",
   "metadata": {},
   "source": [
    "#### A. Get questions and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf653a9-c731-4d0f-a7c8-3d7beb847038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ECB Guide with embeddings and testing questions\n",
    "embeddings = pd.read_pickle(\"ecb_guide_embeddings.pkl\")\n",
    "embeddings['embedding'] = embeddings['embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "\n",
    "questions = pd.read_excel(\"questions_ecb_extended.xlsx\")\n",
    "\n",
    "# Extract relevant parts from questions\n",
    "idx = questions['in_scope'] == 1\n",
    "questions = questions[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42efdc3-367f-400f-8d41-c382f944fe5a",
   "metadata": {},
   "source": [
    "#### B. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f26b26a-3205-43e4-b321-0725655626bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(df, search_phrase):\n",
    "    search_embedding = create_embedding(search_phrase)\n",
    "    df[\"similarity\"] = df[\"embedding\"].apply(\n",
    "        lambda x: cosine_similarity(x, search_embedding))\n",
    "    df = df.sort_values(by='similarity', ascending=False).reset_index()\n",
    "    first_value = df['Index'].iloc[0]\n",
    "\n",
    "    return df, first_value\n",
    "\n",
    "def create_embedding(search_phrase):\n",
    "    return get_embedding(\n",
    "        search_phrase,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "def test_answers(embeddings, questions):\n",
    "    # Create an empty list to store the results\n",
    "    results_list = []\n",
    "    \n",
    "    for index, row in questions.iterrows():\n",
    "        query = row['question']\n",
    "        question_number = row['Index']\n",
    "        df, first_value = search_docs(embeddings, query)\n",
    "\n",
    "        # Create a Boolean mask and find the index of the first occurrence\n",
    "        mask = df['Index'] == question_number\n",
    "        first_index = mask.idxmax() + 1 if mask.any() else 10000\n",
    "\n",
    "       # Append a new dictionary to the results list\n",
    "        results_list.append({\n",
    "            'Question': query,\n",
    "            'question_number': question_number,\n",
    "            'first_value': first_value,\n",
    "            'top_result': int(first_index),\n",
    "            'total_documents': len(df)\n",
    "        })\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Replace NaN values with 1000 in column 'A'\n",
    "    results_df['top_result'].fillna(100000, inplace=True)\n",
    "    results_df['top_result'] = results_df['top_result'].astype(int)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def display_rows(df, top=3):\n",
    "    \"\"\"\n",
    "    Display multiple rows in the DataFrame in the specified format.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the data\n",
    "    - row_indices (list): A list of indices of the rows to display\n",
    "    \n",
    "    \"\"\"\n",
    "    row_indices = list(range(top))\n",
    "    \n",
    "    for i, row_index in enumerate(row_indices):\n",
    "        # Get the values of the specified row from the DataFrame\n",
    "        row_data = df.iloc[row_index]\n",
    "        \n",
    "        # Extract the 'source' and 'text' values from the row\n",
    "        source_value = row_data['full_label']\n",
    "        text_value = row_data['checked_sentence']\n",
    "        \n",
    "        # Display the data as specified\n",
    "        print(f\"Source: {source_value}\\n\")\n",
    "        print(f\"{format_text(text_value)}\\n\")\n",
    "        \n",
    "        # Print separator if not the last row\n",
    "        if i < len(row_indices) - 1:\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "\n",
    "def format_text(text):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Initialize the formatted text and a temporary line\n",
    "    formatted_text = \"\"\n",
    "    line = \"\"\n",
    "    \n",
    "    for word in words:\n",
    "        # If the word is a bullet or special marker, start a new line with spacing\n",
    "        special_markers = {\"(a)\", \"(b)\", \"(c)\", \"(d)\", \"(e)\", \"(f)\", \"(g)\", \"(h)\", \"(i)\", \"(j)\", \n",
    "                           \"(i)\", \"(ii)\", \"(iii)\", \"(iv)\", \"(v)\", \"(vi)\",\n",
    "                          \"(vii)\", \"(viii)\", \"(ix)\", \"(x)\", \"(xi)\", \"(xii)\",\n",
    "                          \"•\"}\n",
    "\n",
    "        if word in special_markers:\n",
    "            formatted_text += line + \"\\n\\n\"  # Add two new lines for spacing\n",
    "            line = word + \" \"\n",
    "        # If adding the word does not exceed 80 characters, add it to the line\n",
    "        elif len(line + word) <= 100:\n",
    "            line += word + \" \"\n",
    "        # If adding the word exceeds 80 characters, start a new line\n",
    "        else:\n",
    "            formatted_text += line + \"\\n\"\n",
    "            line = word + \" \"\n",
    "    # Add the last line to the formatted text\n",
    "    formatted_text += line\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "def frequency_analysis(places):\n",
    "    top_1 = sum(places == 1)\n",
    "    top_5 = sum(places <= 5)\n",
    "    top_10 = sum(places <= 10)\n",
    "    top_1000 = sum(places <= 10000)\n",
    "    \n",
    "    print(f\"Occurrences in Top 1: {top_1}\")\n",
    "    print(f\"Occurrences in Top 5: {top_5}\")\n",
    "    print(f\"Occurrences in Top 10: {top_10}\")\n",
    "    print(f\"Occurrences in Top 1000: {top_1000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d0b84-ec48-4ac3-8d6d-56650023c7a9",
   "metadata": {},
   "source": [
    "#### C. Conduct testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5932032-7b3a-42af-85b1-5fa5fc78d6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Document Retrieval Performance: finding relevant document out of 1121 options\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop_10\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_result\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m✔️\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m❌\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m     Document Retrieval Performance: finding relevant document out of 1121 options\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtest_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRank/Total\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTop_10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:5773\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5771\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m-> 5773\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5774\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   5776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\sample.py:150\u001b[0m, in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[0;32m    151\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    152\u001b[0m )\n",
      "File \u001b[1;32mmtrand.pyx:965\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# Comppute the results\n",
    "test_results = test_answers(embeddings, questions)\n",
    "\n",
    "# Add stats\n",
    "test_results['Rank/Total'] = test_results['top_result'].astype(str) + \" / \" + test_results['total_documents'].astype(str)\n",
    "test_results['Top_10'] = test_results['top_result'].apply(lambda x: '✔️' if x <= 10 else '❌')\n",
    "\n",
    "print('     Document Retrieval Performance: finding relevant document out of 1121 options')\n",
    "test_results[['Question', 'Rank/Total', 'Top_10']].sample(len(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be0bcc-72a0-4d52-8f0b-39bc327ac83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top results\n",
    "frequency_analysis(test_results['top_result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57be324-bcb4-45f6-a50f-3bf50f7cc4f0",
   "metadata": {},
   "source": [
    "#### D. Peform manual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9b00c-014d-4474-99aa-662029dc8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1\n",
    "query = \"What does the term 'initial validation' refer to?\"\n",
    "df, first_value = search_docs(embeddings, query)\n",
    "\n",
    "display_rows(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b4821-ba0d-4dcf-a757-0f7181e048b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2\n",
    "query = 'what are reference dates for EAD/CCF modelling?'\n",
    "df, first_value = search_docs(embeddings, query)\n",
    "\n",
    "display_rows(df, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
